{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030b728b",
   "metadata": {},
   "source": [
    "# 4.2 VectorDBBench åŸºå‡†æµ‹è¯•å®æˆ˜\n",
    "\n",
    "æœ¬èŠ‚å°†å¸¦ä½ äº†è§£å¹¶å®è·µ VectorDBBench è¿™ä¸€ä¸»æµå‘é‡æ•°æ®åº“åŸºå‡†æµ‹è¯•å·¥å…·çš„éƒ¨ç½²ä¸ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a417c4",
   "metadata": {},
   "source": [
    "## 4.2.1 VectorDBBench ç®€ä»‹\n",
    "\n",
    "VectorDBBenchï¼ˆVDBBenchï¼‰æ˜¯ä¸€ä¸ªé¢å‘ä¸»æµå‘é‡æ•°æ®åº“å’Œäº‘æœåŠ¡çš„å¼€æºåŸºå‡†æµ‹è¯•å·¥å…·ï¼Œæ”¯æŒå¤šç§æ•°æ®åº“çš„æ€§èƒ½ä¸æ€§ä»·æ¯”å¯¹æ¯”ï¼Œæä¾›å¯è§†åŒ–ç•Œé¢å’Œä¸°å¯Œçš„æµ‹è¯•åœºæ™¯ï¼Œæ–¹ä¾¿ç”¨æˆ·å¤ç°ç»“æœæˆ–æµ‹è¯•æ–°ç³»ç»Ÿã€‚\n",
    "\n",
    "- æ”¯æŒå¤šç§æ•°æ®åº“ï¼ˆå¦‚ Milvusã€Zilliz Cloudã€Qdrantã€Weaviateã€PgVectorã€Redisã€Chroma ç­‰ï¼‰\n",
    "- æä¾›æ’å…¥ã€æœç´¢ã€è¿‡æ»¤æœç´¢ã€æµå¼æœç´¢ç­‰å¤šç§æµ‹è¯•åœºæ™¯\n",
    "- å†…ç½®å¤šç§å…¬å¼€æ•°æ®é›†ï¼ˆå¦‚ SIFTã€GISTã€Cohereã€OpenAI C4 ç­‰ï¼‰\n",
    "- æ”¯æŒå¯è§†åŒ–ç•Œé¢ï¼Œä¾¿äºé…ç½®æµ‹è¯•ã€æŸ¥çœ‹å’Œå¯¹æ¯”æµ‹è¯•ç»“æœ\n",
    "\n",
    "ä¸»è¦ç‰¹æ€§ï¼š\n",
    "1. ç®€å•æ˜“ç”¨çš„ Web UIï¼Œæ”¯æŒæµ‹è¯•é…ç½®å’Œç»“æœå¯è§†åŒ–åˆ†æ\n",
    "2. æ ‡å‡†åŒ–çš„æµ‹è¯•æµç¨‹å’ŒæŒ‡æ ‡é‡‡é›†ï¼Œæ”¯æŒå¤šåœºæ™¯æ‰©å±•ï¼ˆå¦‚è¿‡æ»¤ã€æµå¼ï¼‰\n",
    "3. æ”¯æŒå¤šç§ä¸»æµå’Œæ–°å…´å‘é‡æ•°æ®åº“ï¼Œä¾¿äºæ¨ªå‘å¯¹æ¯”\n",
    "\n",
    "æ›´å¤šä»‹ç»è¯¦è§ [å®˜æ–¹æ–‡æ¡£](https://github.com/zilliztech/VectorDBBench)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d0c4d",
   "metadata": {},
   "source": [
    "## 4.2.2 VectorDBBench éƒ¨ç½²ï¼ˆå¤šç§æ•°æ®åº“çš„ clientï¼‰\n",
    "\n",
    "### ç¯å¢ƒè¦æ±‚\n",
    "- Python >= 3.11\n",
    "\n",
    "### å®‰è£…\n",
    "ä»…å®‰è£… Milvus/Zilliz Cloud å®¢æˆ·ç«¯ï¼š\n",
    "```shell\n",
    "pip install vectordb-bench\n",
    "```\n",
    "\n",
    "å®‰è£…æ‰€æœ‰æ”¯æŒçš„æ•°æ®åº“å®¢æˆ·ç«¯ï¼ˆå¦‚éœ€å¯¹æ¯”å¤šç§æ•°æ®åº“ï¼‰ï¼š\n",
    "```shell\n",
    "pip install vectordb-bench[all]\n",
    "```\n",
    "\n",
    "å®‰è£…æŒ‡å®šæ•°æ®åº“å®¢æˆ·ç«¯ï¼ˆå¦‚ Qdrantï¼‰ï¼š\n",
    "```shell\n",
    "pip install vectordb-bench[qdrant]\n",
    "```\n",
    "\n",
    "æ”¯æŒçš„æ•°æ®åº“å®¢æˆ·ç«¯åŠå®‰è£…å‘½ä»¤å¦‚ä¸‹ï¼š\n",
    "\n",
    "| æ•°æ®åº“å®¢æˆ·ç«¯ | å®‰è£…å‘½ä»¤ |\n",
    "|-------------|----------|\n",
    "| pymilvus, zilliz_cloud | `pip install vectordb-bench` |\n",
    "| all         | `pip install vectordb-bench[all]` |\n",
    "| qdrant      | `pip install vectordb-bench[qdrant]` |\n",
    "| pinecone    | `pip install vectordb-bench[pinecone]` |\n",
    "| weaviate    | `pip install vectordb-bench[weaviate]` |\n",
    "| elastic, aliyun_elasticsearch | `pip install vectordb-bench[elastic]` |\n",
    "| pgvector, pgvectorscale, pgdiskann, alloydb | `pip install vectordb-bench[pgvector]` |\n",
    "| redis       | `pip install vectordb-bench[redis]` |\n",
    "| chromadb    | `pip install vectordb-bench[chromadb]` |\n",
    "| awsopensearch | `pip install vectordb-bench[opensearch]` |\n",
    "| oceanbase   | `pip install vectordb-bench[oceanbase]` |\n",
    "| ...         | ... |\n",
    "\n",
    "æ›´å¤šæ•°æ®åº“æ”¯æŒå’Œå®‰è£…æ–¹å¼è¯¦è§å®˜æ–¹ READMEã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b49595",
   "metadata": {},
   "source": [
    "## 4.2.3 VectorDBBench ç½‘é¡µå¯åŠ¨åŠåŠŸèƒ½ä»‹ç»\n",
    "\n",
    "### å¯åŠ¨ Web ç•Œé¢\n",
    "\n",
    "å®‰è£…å®Œæˆåï¼Œç›´æ¥è¿è¡Œï¼š\n",
    "```shell\n",
    "init_bench\n",
    "```\n",
    "æˆ–\n",
    "```shell\n",
    "python -m vectordb_bench\n",
    "```\n",
    "\n",
    "é»˜è®¤ä¼šå¯åŠ¨æœ¬åœ° Web æœåŠ¡ï¼ˆå¦‚ http://localhost:8501ï¼‰ï¼Œæ‰“å¼€æµè§ˆå™¨å³å¯è®¿é—®ã€‚\n",
    "\n",
    "### ä¸»è¦åŠŸèƒ½æ¨¡å—\n",
    "- **Run Test**ï¼šé€‰æ‹©æ•°æ®åº“ã€å¡«å†™è¿æ¥ä¿¡æ¯ã€é€‰æ‹©æµ‹è¯•ç”¨ä¾‹ï¼Œå‘èµ·åŸºå‡†æµ‹è¯•ã€‚æ”¯æŒå¤šæ•°æ®åº“ã€å¤šç”¨ä¾‹ã€å¤šæ•°æ®é›†ç»„åˆæµ‹è¯•ã€‚\n",
    "- **Result**ï¼šæŸ¥çœ‹æ‰€æœ‰æµ‹è¯•ç»“æœï¼Œæ”¯æŒå¤šè½®å¯¹æ¯”å’Œç­›é€‰ï¼Œæ”¯æŒ QPSã€å»¶è¿Ÿã€æ€§ä»·æ¯”ç­‰å¤šç»´åº¦å±•ç¤ºã€‚\n",
    "- **Custom Dataset**ï¼šè‡ªå®šä¹‰æ•°æ®é›†å’Œæµ‹è¯•ç”¨ä¾‹ï¼Œæ”¯æŒè¯¦ç»†å‚æ•°é…ç½®ï¼ˆå¦‚ç»´åº¦ã€æ•°æ®é‡ã€æ ‡ç­¾åˆ†å¸ƒç­‰ï¼‰ã€‚\n",
    "- **Quries Per Dollar**ï¼šå±•ç¤ºæ¯ç¾å…ƒå¯å¤„ç†çš„æŸ¥è¯¢é‡ï¼Œä¾¿äºæ€§ä»·æ¯”åˆ†æã€‚\n",
    "- **Tables**ï¼šä»¥è¡¨æ ¼å½¢å¼å¯¹æ¯”ä¸åŒæ•°æ®é›†ä¸‹çš„å„é¡¹æŒ‡æ ‡ã€‚\n",
    "- **Concurrent Performance**ï¼šå±•ç¤ºä¸åŒå¹¶å‘ä¸‹ QPS ä¸å»¶è¿Ÿçš„å˜åŒ–è¶‹åŠ¿ã€‚\n",
    "- **Label Filter Performance**ï¼šå±•ç¤ºä¸åŒæ ‡ç­¾è¿‡æ»¤æ¯”ä¾‹ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚\n",
    "- **Int Filter Performance**ï¼šå±•ç¤ºä¸åŒæ•´æ•°è¿‡æ»¤æ¯”ä¾‹ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚\n",
    "- **Streaming Performance**ï¼šå±•ç¤ºåœ¨æŒç»­æ’å…¥å‹åŠ›ä¸‹çš„æ£€ç´¢æ€§èƒ½ã€‚\n",
    "\n",
    "#### å…¸å‹ç•Œé¢ç¤ºä¾‹\n",
    "\n",
    "![VDBBench ä¸»ç•Œé¢](./images/VectorDBBench.png)\n",
    "\n",
    "![VDBBench ç»“æœé¡µé¢](https://github.com/zilliztech/VectorDBBench/assets/105927039/8a981327-c1c6-4796-8a85-c86154cb5472)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed65c1d",
   "metadata": {},
   "source": [
    "## 4.2.4 ä½¿ç”¨é»˜è®¤æ•°æ®é›†è¿›è¡ŒåŸºå‡†æµ‹è¯•\n",
    "\n",
    "### æµ‹è¯•æµç¨‹è¯´æ˜\n",
    "VDBBench æ ‡å‡†æµ‹è¯•æµç¨‹åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š\n",
    "\n",
    "1. **Loadï¼ˆæ’å…¥+ä¼˜åŒ–ï¼‰**ï¼šå•è¿›ç¨‹ä¸²è¡Œæ’å…¥å…¨éƒ¨æ•°æ®ï¼Œè®°å½•æ’å…¥è€—æ—¶ï¼ˆinsert_durationï¼‰ï¼›éƒ¨åˆ†æ•°æ®åº“è¿˜ä¼šè¿›è¡Œç´¢å¼•ä¼˜åŒ–ï¼Œè®°å½•ä¼˜åŒ–è€—æ—¶ï¼ˆoptimize_durationï¼‰ã€‚æ€»è€—æ—¶ï¼ˆload_durationï¼‰åæ˜ æ•°æ®åº“ä»é›¶åˆ°å¯æŸ¥è¯¢çš„æ•´ä½“åŠ è½½èƒ½åŠ›ã€‚\n",
    "2. **Serial Search Testï¼ˆä¸²è¡Œæ£€ç´¢ï¼‰**ï¼šå•è¿›ç¨‹ä¸²è¡Œæ£€ç´¢ï¼Œè®°å½•æ¯æ¬¡æŸ¥è¯¢çš„å¬å›ç‡ï¼ˆrecallï¼‰å’Œå»¶è¿Ÿï¼ˆlatency_p99ï¼‰ã€‚p99 å»¶è¿Ÿå…³æ³¨æœ€æ…¢çš„ 1% è¯·æ±‚ï¼Œé€‚åˆé«˜è¦æ±‚åœºæ™¯ã€‚\n",
    "3. **Concurrent Search Testï¼ˆå¹¶å‘æ£€ç´¢ï¼‰**ï¼šå¤šè¿›ç¨‹å¹¶å‘æ£€ç´¢ï¼Œé€æ­¥æå‡å¹¶å‘åº¦ï¼ˆå¦‚ 1~80ï¼‰ï¼Œæ¯ç»„è¿è¡Œ 30 ç§’ï¼Œè®°å½•ä¸åŒå¹¶å‘ä¸‹çš„ QPS å’Œå»¶è¿Ÿï¼Œæœ€ç»ˆå–æœ€å¤§ QPS ä½œä¸º max-qpsã€‚\n",
    "\n",
    "æ­¤å¤–è¿˜æ”¯æŒï¼š\n",
    "- **Filter Search Test**ï¼šåœ¨æ£€ç´¢æ—¶å¢åŠ æ ‡ç­¾æˆ–æ•´æ•°è¿‡æ»¤æ¡ä»¶ï¼Œè€ƒå¯Ÿä¸åŒè¿‡æ»¤æ¯”ä¾‹ä¸‹çš„æ€§èƒ½å˜åŒ–ã€‚\n",
    "- **Streaming Search Test**ï¼šåœ¨æŒç»­æ’å…¥å‹åŠ›ä¸‹åˆ†é˜¶æ®µè¿›è¡Œæ£€ç´¢ï¼Œè€ƒå¯Ÿæ•°æ®åº“åœ¨æµå¼å†™å…¥åœºæ™¯ä¸‹çš„æ£€ç´¢èƒ½åŠ›ã€‚\n",
    "\n",
    "### å®è·µæ­¥éª¤\n",
    "1. å¯åŠ¨ Web ç•Œé¢åï¼Œè¿›å…¥ **Run Test** é¡µé¢\n",
    "2. é€‰æ‹©è¦æµ‹è¯•çš„æ•°æ®åº“ç³»ç»Ÿï¼ˆå¦‚ Milvusã€Qdrantã€PgVector ç­‰ï¼‰ï¼Œå¡«å†™è¿æ¥ä¿¡æ¯\n",
    "3. é€‰æ‹©æµ‹è¯•ç”¨ä¾‹ï¼ˆå¦‚ Capacityã€Performanceã€Filteringã€Streaming ç­‰ï¼‰ï¼Œå¯å¤šé€‰\n",
    "4. é€‰æ‹©é»˜è®¤æ•°æ®é›†ï¼ˆå¦‚ SIFTã€GISTã€Cohereã€OpenAI C4 ç­‰ï¼‰\n",
    "5. å¡«å†™ Task Labelï¼Œç‚¹å‡»æäº¤ï¼Œç­‰å¾…æµ‹è¯•å®Œæˆ\n",
    "\n",
    "### æ³¨æ„äº‹é¡¹\n",
    "- é»˜è®¤æ•°æ®é›†å·²å†…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨ä¸Šä¼ \n",
    "- å¯æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©ä¸åŒçš„æµ‹è¯•ç”¨ä¾‹å’Œæ•°æ®è§„æ¨¡\n",
    "- å»ºè®®æµ‹è¯•å®¢æˆ·ç«¯ä¸æ•°æ®åº“æœåŠ¡éƒ¨ç½²åœ¨åŒä¸€å±€åŸŸç½‘ï¼Œå‡å°‘ç½‘ç»œå»¶è¿Ÿå½±å“\n",
    "\n",
    "æµ‹è¯•å®Œæˆåï¼Œå¯åœ¨ **Result** é¡µé¢æŸ¥çœ‹è¯¦ç»†ç»“æœå’Œå¯¹æ¯”åˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3c5c0",
   "metadata": {},
   "source": [
    "## 4.2.5 ä½¿ç”¨ Custom æ•°æ®é›†è¿›è¡ŒåŸºå‡†æµ‹è¯•\n",
    "\n",
    "### 4.2.5.1 æ•°æ®å‡†å¤‡\n",
    "\n",
    "#### è„šæœ¬ç”Ÿæˆåˆå§‹æ•°æ®\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_csv(num_records: int, dim: int, filename: str):\n",
    "    ids = range(num_records)\n",
    "    vectors = np.random.rand(num_records, dim).round(6)  # ä¿ç•™6ä½å°æ•°\n",
    "    emb_str = [str(list(vec)) for vec in vectors]\n",
    "    df = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'emb': emb_str\n",
    "    })\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"ç”Ÿæˆæ–‡ä»¶ {filename} ï¼Œå…± {num_records} æ¡æ•°æ®ï¼Œå‘é‡ç»´åº¦ {dim}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_records = 3000  # ç”Ÿæˆæ•°æ®çš„æ•°é‡\n",
    "    dim = 768           # å‘é‡ç»´åº¦\n",
    "\n",
    "    generate_csv(num_records, dim, \"train.csv\")\n",
    "    generate_csv(num_records, dim, \"test.csv\")\n",
    "\n",
    "```\n",
    "\n",
    "#### è‡ªå·±å‡†å¤‡åˆå§‹æ•°æ®\n",
    "æ•°æ®è¦æ±‚ï¼š\n",
    "##### **1. CSV æ ¼å¼**\n",
    "\n",
    "- ç¬¬ä¸€åˆ—ä¸º **id**ï¼ˆå”¯ä¸€æ ‡è¯†ç¬¦ï¼‰\n",
    "- ç¬¬äºŒåˆ—ä¸º **vector**ï¼ˆå­—ç¬¦ä¸²å½¢å¼çš„æµ®ç‚¹æ•°ç»„ï¼Œå¦‚ `[0.1, 0.2, 0.3, ...]`ï¼‰\n",
    "- å…¶ä»–åˆ—å¯é€‰ï¼ˆmetadataã€æ ‡ç­¾ï¼‰\n",
    "\n",
    "**ç¤ºä¾‹ï¼š**\n",
    "\n",
    "```\n",
    "id,emb,label\n",
    "1,\"[0.12,0.56,0.89,...]\",A\n",
    "2,\"[0.33,0.48,0.90,...]\",B\n",
    "```\n",
    "\n",
    "##### **2. NPY æ ¼å¼**\n",
    "\n",
    "- ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œshape = `(num_vectors, dim)`\n",
    "- å‘é‡é¡ºåºé»˜è®¤ä» 0 å¼€å§‹åˆ†é… id\n",
    "- æ ‡ç­¾å¯å•ç‹¬æä¾›ä¸€ä¸ª CSVï¼ˆid,labelï¼‰\n",
    "\n",
    "**ç¤ºä¾‹ï¼š**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "vectors = np.random.rand(10000, 768).astype('float32')\n",
    "np.save(\"vectors.npy\", vectors)\n",
    "```\n",
    "### 4.2.5.2 ä½¿ç”¨è„šæœ¬è½¬æ¢æ•°æ®æ–‡ä»¶æ ¼å¼\n",
    "- å®‰è£…ä¾èµ–ï¼š\n",
    "\n",
    "```\n",
    "pip install numpy pandas faiss-cpu\n",
    "```\n",
    "\n",
    "- å¯åŠ¨å‘½ä»¤ï¼š\n",
    "\n",
    "```shell\n",
    "python convert_to_vdb_format.py \\\n",
    "  --train data/train.csv \\\n",
    "  --test data/test.csv \\\n",
    "  --out datasets/custom \\\n",
    "  --topk 10\n",
    "```\n",
    "\n",
    "- å‚æ•°è¯´æ˜ï¼š\n",
    "\n",
    "| å‚æ•°å     | æ˜¯å¦å¿…å¡« | ç±»å‹   | è¯´æ˜                                                         | é»˜è®¤å€¼ |\n",
    "| ---------- | -------- | ------ | ------------------------------------------------------------ | ------ |\n",
    "| `--train`  | æ˜¯       | å­—ç¬¦ä¸² | è®­ç»ƒæ•°æ®è·¯å¾„ï¼Œæ”¯æŒCSVæˆ–NPYæ ¼å¼ã€‚CSVéœ€åŒ…å«`emb`åˆ—ï¼Œè‹¥æ— `id`åˆ—ä¼šè‡ªåŠ¨ç”Ÿæˆ | æ—      |\n",
    "| `--test`   | æ˜¯       | å­—ç¬¦ä¸² | æŸ¥è¯¢æ•°æ®è·¯å¾„ï¼Œæ”¯æŒCSVæˆ–NPYæ ¼å¼ã€‚æ ¼å¼åŒè®­ç»ƒæ•°æ®               | æ—      |\n",
    "| `--out`    | æ˜¯       | å­—ç¬¦ä¸² | è¾“å‡ºç›®å½•è·¯å¾„ï¼Œä¿å­˜è½¬æ¢åçš„parquetæ–‡ä»¶åŠé‚»å±…ç´¢å¼•æ–‡ä»¶          | æ—      |\n",
    "| `--labels` | å¦       | å­—ç¬¦ä¸² | æ ‡ç­¾CSVè·¯å¾„ï¼Œå¿…é¡»åŒ…å«`labels`åˆ—ï¼ˆæ ¼å¼ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰ï¼Œç”¨äºä¿å­˜æ ‡ç­¾ | æ—      |\n",
    "| `--topk`   | å¦       | æ•´æ•°   | è®¡ç®—æœ€è¿‘é‚»æ—¶è¿”å›çš„é‚»å±…æ•°é‡                                   | 10     |\n",
    "- è¾“å‡ºç›®å½•ç»“æ„\n",
    "\n",
    "```\n",
    "datasets/custom/\n",
    "â”œâ”€â”€ train.parquet          # è®­ç»ƒå‘é‡\n",
    "â”œâ”€â”€ test.parquet           # æŸ¥è¯¢å‘é‡\n",
    "â”œâ”€â”€ neighbors.parquet      # Ground Truth\n",
    "â””â”€â”€ scalar_labels.parquet  # å¯é€‰æ ‡ç­¾\n",
    "```\n",
    "- è„šæœ¬ä»£ç \n",
    "```python\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from ast import literal_eval\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def load_csv(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    if 'emb' not in df.columns:\n",
    "        raise ValueError(f\"CSV æ–‡ä»¶ä¸­ç¼ºå°‘ 'emb' åˆ—ï¼š{path}\")\n",
    "    df['emb'] = df['emb'].apply(literal_eval)\n",
    "    if 'id' not in df.columns:\n",
    "        df.insert(0, 'id', range(len(df)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_npy(path: str):\n",
    "    arr = np.load(path)\n",
    "    df = pd.DataFrame({\n",
    "        'id': range(arr.shape[0]),\n",
    "        'emb': arr.tolist()\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_vectors(path: str) -> pd.DataFrame:\n",
    "    if path.endswith('.csv'):\n",
    "        return load_csv(path)\n",
    "    elif path.endswith('.npy'):\n",
    "        return load_npy(path)\n",
    "    else:\n",
    "        raise ValueError(f\"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {path}\")\n",
    "\n",
    "\n",
    "def compute_ground_truth(train_vectors: np.ndarray, test_vectors: np.ndarray, top_k: int = 10):\n",
    "    dim = train_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(train_vectors)\n",
    "    _, indices = index.search(test_vectors, top_k)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def save_ground_truth(df_path: str, indices: np.ndarray):\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": np.arange(indices.shape[0]),\n",
    "        \"neighbors_id\": indices.tolist()\n",
    "    })\n",
    "    df.to_parquet(df_path, index=False)\n",
    "    print(f\"âœ… Ground truth ä¿å­˜æˆåŠŸ: {df_path}\")\n",
    "\n",
    "\n",
    "def main(train_path: str, test_path: str, output_dir: str,\n",
    "         label_path: Optional[str] = None, top_k: int = 10):\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # åŠ è½½è®­ç»ƒå’ŒæŸ¥è¯¢æ•°æ®\n",
    "    print(\"ğŸ“¥ åŠ è½½è®­ç»ƒæ•°æ®...\")\n",
    "    train_df = load_vectors(train_path)\n",
    "    print(\"ğŸ“¥ åŠ è½½æŸ¥è¯¢æ•°æ®...\")\n",
    "    test_df = load_vectors(test_path)\n",
    "\n",
    "    # å‘é‡æå–å¹¶è½¬æ¢ä¸º numpy\n",
    "    train_vectors = np.array(train_df['emb'].to_list(), dtype='float32')\n",
    "    test_vectors = np.array(test_df['emb'].to_list(), dtype='float32')\n",
    "\n",
    "    # ä¿å­˜ä¿ç•™æ‰€æœ‰å­—æ®µçš„ parquet æ–‡ä»¶\n",
    "    train_df.to_parquet(os.path.join(output_dir, 'train.parquet'), index=False)\n",
    "    print(f\"âœ… train.parquet ä¿å­˜æˆåŠŸï¼Œå…± {len(train_df)} æ¡è®°å½•\")\n",
    "\n",
    "    test_df.to_parquet(os.path.join(output_dir, 'test.parquet'), index=False)\n",
    "    print(f\"âœ… test.parquet ä¿å­˜æˆåŠŸï¼Œå…± {len(test_df)} æ¡è®°å½•\")\n",
    "\n",
    "    # è®¡ç®— ground truth\n",
    "    print(\"ğŸ” è®¡ç®— Ground Truthï¼ˆæœ€è¿‘é‚»ï¼‰...\")\n",
    "    gt_indices = compute_ground_truth(train_vectors, test_vectors, top_k=top_k)\n",
    "    save_ground_truth(os.path.join(output_dir, 'neighbors.parquet'), gt_indices)\n",
    "\n",
    "    # åŠ è½½å¹¶ä¿å­˜æ ‡ç­¾æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "    if label_path:\n",
    "        print(\"ğŸ“¥ åŠ è½½æ ‡ç­¾æ–‡ä»¶...\")\n",
    "        label_df = pd.read_csv(label_path)\n",
    "        if 'labels' not in label_df.columns:\n",
    "            raise ValueError(\"æ ‡ç­¾æ–‡ä»¶ä¸­å¿…é¡»åŒ…å« 'labels' åˆ—\")\n",
    "        label_df['labels'] = label_df['labels'].apply(literal_eval)\n",
    "        label_df.to_parquet(os.path.join(output_dir, 'scalar_labels.parquet'), index=False)\n",
    "        print(\"âœ… æ ‡ç­¾æ–‡ä»¶å·²ä¿å­˜ä¸º scalar_labels.parquet\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"å°†CSV/NPYå‘é‡è½¬æ¢ä¸ºVectorDBBenchæ•°æ®æ ¼å¼ (ä¿ç•™æ‰€æœ‰åˆ—)\")\n",
    "    parser.add_argument(\"--train\", required=True, help=\"è®­ç»ƒæ•°æ®è·¯å¾„ï¼ˆCSV æˆ– NPYï¼‰\")\n",
    "    parser.add_argument(\"--test\", required=True, help=\"æŸ¥è¯¢æ•°æ®è·¯å¾„ï¼ˆCSV æˆ– NPYï¼‰\")\n",
    "    parser.add_argument(\"--out\", required=True, help=\"è¾“å‡ºç›®å½•\")\n",
    "    parser.add_argument(\"--labels\", help=\"æ ‡ç­¾CSVè·¯å¾„ï¼ˆå¯é€‰ï¼‰\")\n",
    "    parser.add_argument(\"--topk\", type=int, default=10, help=\"Ground truth\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args.train, args.test, args.out, args.labels, args.topk)\n",
    "\n",
    "```\n",
    "### 4.2.5.3 è®¾ç½® Custom æ•°æ®å¹¶æµ‹è¯•\n",
    "- è¿›å…¥ Web UI é¦–é¡µï¼Œé€‰æ‹©ä¸»é¡µä¸­çš„ **Custom Dataset**ï¼š\n",
    "\n",
    "![image-20250809160755529](./images/image-20250809160755529.png)\n",
    "\n",
    "- é€‰æ‹©ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° **Custom Dataset** ç›¸å…³çš„è§£é‡Šä»¥åŠéœ€è¦å¡«å†™çš„å†…å®¹ï¼š\n",
    "\n",
    "![image-20250809160941449](./images/image-20250809160941449.png)\n",
    "\n",
    "- å‚æ•°è¯¦è§£\n",
    "\n",
    "| å­—æ®µå                      | å«ä¹‰                                        | å¡«å†™å»ºè®®                                                     |\n",
    "| --------------------------- | ------------------------------------------- | ------------------------------------------------------------ |\n",
    "| **Name**                    | æ•°æ®é›†åç§°ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰                      | ä»»æ„ï¼Œä¾‹å¦‚ `my_custom_dataset`                               |\n",
    "| **Folder Path**             | æ•°æ®é›†æ‰€åœ¨æ–‡ä»¶å¤¹è·¯å¾„                        | å¦‚ `/data/datasets/custom`                                   |\n",
    "| **dim**                     | å‘é‡ç»´åº¦                                    | ä¸æ•°æ®æ–‡ä»¶ä¸€è‡´ï¼Œå¦‚ `768`                                     |\n",
    "| **size**                    | å‘é‡æ•°é‡ï¼ˆå¯é€‰ï¼‰                            | å¯ç•™ç©ºï¼Œç³»ç»Ÿå¯è‡ªåŠ¨è¯»å–                                       |\n",
    "| **metric type**             | ç›¸ä¼¼åº¦åº¦é‡æ–¹å¼                              | å¸¸ç”¨ `L2`ï¼ˆæ¬§å¼è·ç¦»ï¼‰æˆ– `IP`ï¼ˆå†…ç§¯ï¼‰                         |\n",
    "| **train file name**         | è®­ç»ƒé›†æ–‡ä»¶åï¼ˆä¸å¸¦ `.parquet` åç¼€ï¼‰        | å¦‚æœæ˜¯ `train.parquet`ï¼Œå¡« `train`ã€‚å¤šä¸ªæ–‡ä»¶ç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ `train1,train2` |\n",
    "| **test file name**          | æŸ¥è¯¢é›†æ–‡ä»¶åï¼ˆä¸å¸¦ `.parquet` åç¼€ï¼‰        | å¦‚æœæ˜¯ `test.parquet`ï¼Œå¡« `test`                             |\n",
    "| **ground truth file name**  | Ground Truth æ–‡ä»¶åï¼ˆä¸å¸¦ `.parquet` åç¼€ï¼‰ | å¦‚æœæ˜¯ `neighbors.parquet`ï¼Œå¡« `neighbors`                   |\n",
    "| **train id name**           | è®­ç»ƒæ•°æ® ID åˆ—å                            | ä¸€èˆ¬æ˜¯ `id`                                                  |\n",
    "| **train emb name**          | è®­ç»ƒæ•°æ®å‘é‡åˆ—å                            | å¦‚æœè„šæœ¬ç”Ÿæˆçš„åˆ—åæ˜¯ `emb`ï¼Œå¡« `emb`                         |\n",
    "| **test emb name**           | æµ‹è¯•æ•°æ®å‘é‡åˆ—å                            | ä¸€èˆ¬ä¸ train emb name ä¸€è‡´ï¼Œå¦‚ `emb`                         |\n",
    "| **ground truth emb name**   | Ground Truth ä¸­çš„è¿‘é‚»åˆ—å                   | å¦‚æœåˆ—åæ˜¯ `neighbors_id`ï¼Œå¡« `neighbors_id`                 |\n",
    "| **scalar labels file name** | ï¼ˆå¯é€‰ï¼‰æ ‡ç­¾æ–‡ä»¶åï¼ˆä¸å¸¦ `.parquet` åç¼€ï¼‰  | å¦‚æœç”Ÿæˆäº† `scalar_labels.parquet`ï¼Œå¡« `scalar_labels`ï¼Œå¦åˆ™ç•™ç©º |\n",
    "| **label percentages**       | ï¼ˆå¯é€‰ï¼‰æ ‡ç­¾è¿‡æ»¤æ¯”ä¾‹                        | ä¾‹å¦‚ `0.001,0.02,0.5`ï¼Œæ²¡æœ‰æ ‡ç­¾è¿‡æ»¤éœ€æ±‚ç•™ç©º                  |\n",
    "| **description**             | æ•°æ®é›†è¯´æ˜                                  | å¯å†™ä¸Šä¸šåŠ¡èƒŒæ™¯æˆ–ç”Ÿæˆæ–¹å¼                                     |\n",
    "\n",
    "ç‚¹å‡» **Save** ä¿å­˜ã€‚\n",
    "\n",
    "\n",
    "### 4.2.5.3 é…ç½®æµ‹è¯•æ–¹æ¡ˆå¹¶è¿è¡Œæµ‹è¯•\n",
    "\n",
    "1. åœ¨ Web UI ä¸­è¿›å…¥ **Run Test** é¡µé¢ï¼š\n",
    "\n",
    "   ![image-20250809170426143](./images/image-20250809170426143.png)\n",
    "\n",
    "2. å‹¾é€‰å¹¶å¡«å†™è¦æµ‹è¯•çš„å‘é‡æ•°æ®åº“ï¼Œæœ¬æ–‡ä»¥ milvus ä¸ºä¾‹ï¼š\n",
    "\n",
    "   ![image-20250809170449053](./images/image-20250809170449053.png)\n",
    "\n",
    "3. é€‰æ‹©æˆ‘ä»¬åˆ›å»ºçš„ Custom æ•°æ®é›†ï¼š\n",
    "\n",
    "   ![image-20250809170511831](./images/image-20250809170511831.png)\n",
    "\n",
    "4. è®¾ç½®ä»»åŠ¡æ ‡ç­¾\n",
    "\n",
    "   ![image-20250809170553869](./images/image-20250809170553869.png)\n",
    "\n",
    "5. å¼€å§‹æµ‹è¯•\n",
    "\n",
    "![image-20250809170644233](./images/image-20250809170644233.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d89f95",
   "metadata": {},
   "source": [
    "## 4.2.6 ç»“æœè§£æ\n",
    "#### ä¸»è¦æŒ‡æ ‡è¯´æ˜\n",
    "\n",
    "- QPS (Queries Per Second)ï¼š\n",
    "  - æ¯ç§’å¤„ç†çš„æŸ¥è¯¢æ•°é‡ã€‚QPS æ˜¯è¡¡é‡ç³»ç»ŸæŸ¥è¯¢å¤„ç†èƒ½åŠ›çš„æŒ‡æ ‡ï¼Œè¶Šé«˜çš„ QPS è¡¨ç¤ºç³»ç»Ÿèƒ½å¤Ÿåœ¨å•ä½æ—¶é—´å†…å¤„ç†æ›´å¤šçš„æŸ¥è¯¢ã€‚\n",
    "- Recallï¼š\n",
    "  - æ˜¯æ£€ç´¢ç³»ç»Ÿçš„å‡†ç¡®ç‡æŒ‡æ ‡ï¼Œç”¨æ¥è¡¡é‡æŸ¥è¯¢ç»“æœä¸­è¿”å›çš„ç›¸å…³é¡¹ä¸å®é™…ç›¸å…³é¡¹çš„æ¯”ä¾‹ã€‚Recall è¶Šé«˜ï¼Œè¡¨ç¤ºè¿”å›çš„æŸ¥è¯¢ç»“æœä¸­åŒ…å«æ›´å¤šæ­£ç¡®çš„åŒ¹é…é¡¹ã€‚ç”¨æ¥è¯„ä¼°ç³»ç»Ÿåœ¨è¿‘ä¼¼æŸ¥è¯¢æ—¶çš„æ•ˆæœã€‚\n",
    "- Load Durationï¼š\n",
    "  - æ•°æ®åŠ è½½æ—¶é—´ï¼Œè¡¨ç¤ºå°†æ•°æ®åŠ è½½åˆ°æ•°æ®åº“ä¸­æ‰€èŠ±è´¹çš„æ€»æ—¶é—´ã€‚è¿™ä¸ªæŒ‡æ ‡è¡¡é‡æ•°æ®åº“çš„åŠ è½½æ•ˆç‡ï¼Œé€šå¸¸æ•°æ®é‡è¶Šå¤§ï¼ŒåŠ è½½æ—¶é—´è¶Šé•¿ã€‚\n",
    "- Serial Latency P99ï¼š\n",
    "  - è¿™æ˜¯ 99% çš„æŸ¥è¯¢å¤„ç†æ—¶é—´çš„ä¸Šé™ï¼Œè¡¨ç¤ºç³»ç»Ÿå¤„ç† 99% çš„æŸ¥è¯¢æ‰€éœ€çš„æœ€é•¿æ—¶é—´ï¼ˆ99th percentile latencyï¼‰ã€‚è¿™ä¸ªæŒ‡æ ‡æ˜¯ç”¨æ¥è¡¡é‡ç³»ç»Ÿå“åº”æ—¶é—´çš„ä¸€è‡´æ€§ï¼Œå€¼è¶Šä½ï¼Œç³»ç»Ÿçš„å“åº”è¶Šç¨³å®šã€‚P99 å»¶è¿Ÿè¶Šé«˜æ„å‘³ç€ç³»ç»Ÿå¶å°”ä¼šæœ‰æ…¢æŸ¥è¯¢ã€‚\n",
    "\n",
    "è¯¦ç»†è§„åˆ™å¯å‚è€ƒ [Leaderboard è¯´æ˜](https://zilliz.com/benchmark)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
